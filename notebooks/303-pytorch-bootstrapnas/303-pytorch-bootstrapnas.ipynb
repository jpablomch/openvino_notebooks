{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "git68adWeq4l"
   },
   "source": [
    "# Automated Neural Architecture Search with BootstrapNAS\n",
    "This notebook demonstrates how to use [BootstrapNAS](https://arxiv.org/abs/2112.10878), a capability in NNCF to generate weight-sharing super-networks from pre-trained models. Once the super-network has been generated, BootstrapNAS can train it and search for efficient sub-networks. \n",
    "\n",
    "We will use [MobileNet-V2](https://arxiv.org/abs/1801.04381) pre-trained with CIFAR-10. MobileNet-V2 is an efficient mobile architecture based on inverted residual blocks. Our goal is to discover alternative models, a.k.a., subnetworks, that perform better than the input pre-trained model.\n",
    "\n",
    "\\*BootstrapNAS is an **experimental feature** in NNCF.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://github.com/jpablomch/bootstrapnas/raw/main/architecture.png\" alt=\"BootstrapNAS Architecture\" width=\"800\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "BootstrapNAS (1) takes as input a pre-trained model. (2) It uses this model to generate a weight-sharing super-network. (3) BootstrapNAS then applies a training strategy, and once the super-network has been trained, (4) it searches for efficient subnetworks that satisfy the user's requirements. (5) The configuration of the discovered sub-network(s) is returned to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6M1xndNu-z_2"
   },
   "source": [
    "## Imports and Settings\n",
    "\n",
    "Import NNCF and all auxiliary packages from your Python code.\n",
    "Set a name for the model, and the image width and height that will be used for the network. Also define paths where PyTorch, ONNX and OpenVINO IR versions of the models will be stored. \n",
    "\n",
    "> NOTE: All NNCF logging messages below ERROR level (INFO and WARNING) are disabled to simplify the tutorial. For production use, it is recommended to enable logging, by removing ```set_log_level(logging.ERROR)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BtaM_i2mEB0z",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import warnings  # to disable warnings on export to ONNX\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import nncf  # Important - should be imported directly after torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from bootstrapnas_utils import MobileNetV2, validate, train_epoch\n",
    "\n",
    "from nncf.common.utils.logger import set_log_level\n",
    "set_log_level(logging.ERROR)  # Disables all NNCF info and warning messages\n",
    "\n",
    "from nncf import NNCFConfig\n",
    "from nncf.config.structures import BNAdaptationInitArgs\n",
    "from nncf.experimental.torch.nas.bootstrapNAS import EpochBasedTrainingAlgorithm\n",
    "from nncf.experimental.torch.nas.bootstrapNAS import SearchAlgorithm\n",
    "from nncf.torch import create_compressed_model, register_default_init_args\n",
    "from nncf.torch.initialization import wrap_dataloader_for_init\n",
    "from nncf.torch.model_creation import create_nncf_network\n",
    "\n",
    "from openvino.runtime import Core\n",
    "from torch.jit import TracerWarning\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "from notebook_utils import download_file\n",
    "\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "MODEL_DIR = Path(\"model\")\n",
    "OUTPUT_DIR = Path(\"output\")\n",
    "DATA_DIR = Path(\"data\")\n",
    "BASE_MODEL_NAME = \"mobilenet-V2\"\n",
    "image_size = 32\n",
    "\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Paths where models will be stored\n",
    "fp32_pth_path = Path(MODEL_DIR / (BASE_MODEL_NAME + \"_fp32\")).with_suffix(\".pth\")\n",
    "model_onnx_path = Path(OUTPUT_DIR / (BASE_MODEL_NAME )).with_suffix(\".onnx\")\n",
    "supernet_onnx_path = Path(OUTPUT_DIR / (BASE_MODEL_NAME + \"_supernet\")).with_suffix(\".onnx\")\n",
    "subnet_onnx_path = Path(OUTPUT_DIR / (BASE_MODEL_NAME + \"_subnet\")).with_suffix(\".onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download pre-trained model weights\n",
    "Download the pre-trained weights for MobileNet-V2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# It's possible to train FP32 model from scratch, but it might be slow. So the pre-trained weights are downloaded by default.\n",
    "pretrained_on_cifar10 = True\n",
    "fp32_pth_url = \"http://hsw1.jf.intel.com/share/bootstrapNAS/checkpoints/cifar10/mobilenet_v2.pt\"\n",
    "download_file(fp32_pth_url, directory=MODEL_DIR, filename=fp32_pth_path.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EIo5S145S0Ug",
    "outputId": "9a2db892-eb38-4863-dfdb-560aa12c8232",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prepare CIFAR-10 dataset\n",
    "Next, prepare the CIFAR-10 dataset. The CIFAR-10 dataset contains:\n",
    "* 60,000 images of shape 3x32x32\n",
    "* 10 different classes (6,000 images per class): airplane, automobile, etc. \n",
    "\n",
    "Here, the dataloader is created for both the training and validation dataset which includes normalization, crop, and other transformation.  Each dataloader uses 4 workers and a batch size of 64 for training and 1000 for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-HxsU71bEbLS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_DIR = DATA_DIR / \"cifar10\"\n",
    "\n",
    "image_size = 32\n",
    "size = int(image_size / 0.875)\n",
    "normalize = transforms.Normalize(mean=(0.4914, 0.4822, 0.4465),\n",
    "                                         std=(0.2471, 0.2435, 0.2616))\n",
    "list_val_transforms = [\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ]\n",
    "val_transform = transforms.Compose(list_val_transforms)\n",
    "\n",
    "list_train_transforms = [\n",
    "            transforms.RandomCrop(image_size, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ]\n",
    "    \n",
    "train_transform = transforms.Compose(list_train_transforms)\n",
    "    \n",
    "download = False \n",
    "if not DATASET_DIR.exists(): \n",
    "    download = True\n",
    "\n",
    "train_dataset = datasets.CIFAR10(DATASET_DIR, train=True, transform=train_transform, download=download)\n",
    "val_dataset = datasets.CIFAR10(DATASET_DIR, train=False, transform=val_transform, download=download)\n",
    "\n",
    "batch_size_val = 1000\n",
    "batch_size = 64\n",
    "workers = 4\n",
    "pin_memory = device != 'cpu'\n",
    "val_sampler = torch.utils.data.SequentialSampler(val_dataset) \n",
    "train_sampler = None\n",
    "train_shuffle = None\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size_val, shuffle=False,\n",
    "        num_workers=workers, pin_memory=pin_memory,\n",
    "        sampler=val_sampler, drop_last=False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=batch_size, shuffle=train_shuffle,\n",
    "            num_workers=workers, pin_memory=pin_memory, sampler=train_sampler, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZX2GAh3W7ZT",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<!-- ## Pre-train Floating-Point Model\n",
    "Using NNCF for model compression assumes that the user has a pre-trained model and a training pipeline.\n",
    "\n",
    "Here we demonstrate one possible training pipeline: a ResNet-18 model pre-trained on 1000 classes from ImageNet is fine-tuned with 200 classes from Tiny-Imagenet. \n",
    "\n",
    "Subsequently, the training and validation functions will be reused as is for quantization-aware training.\n",
    " -->\n",
    " \n",
    " ## Generate Super-network from pre-trained model\n",
    " \n",
    "Using NNCF for model compression assumes that the user has a pre-trained model and a training pipeline. Next, we demonstrate one possible training pipeline.\n",
    "\n",
    "\n",
    "### Evaluate pre-trained model\n",
    "Load the pretrained model and evaluate using validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetV2()\n",
    "state_dict = torch.load(fp32_pth_path)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Test exporting original model to ONNX\n",
    "dummy_input = torch.randn(1, 3, image_size, image_size).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_top1_acc, _, _ = validate(model, device, val_loader, criterion) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train supernetwork\n",
    "We use the pre-trained MobileNet-V2 model to generate a weight-sharing super-network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "train_steps = 10\n",
    "\n",
    "config = {\n",
    "            \"device\": device,\n",
    "            \"input_info\": {\n",
    "                \"sample_size\": [1, 3, 32, 32],\n",
    "            },\n",
    "            \"checkpoint_save_dir\": OUTPUT_DIR,\n",
    "            \"bootstrapNAS\": {\n",
    "                \"training\": {\n",
    "                    # \"algorithm\": \"progressive_shrinking\",\n",
    "                    \"batchnorm_adaptation\": {\n",
    "                        \"num_bn_adaptation_samples\": 2\n",
    "                    },\n",
    "                    \"schedule\": {\n",
    "                        \"list_stage_descriptions\": [\n",
    "                            {\"train_dims\": [\"depth\"], \"epochs\": 1},\n",
    "                            # {\"train_dims\": [\"depth\"], \"epochs\": 1, \"depth_indicator\": 2},\n",
    "                            # {\"train_dims\": [\"depth\", \"width\"], \"epochs\": 1, \"depth_indicator\": 2, \"reorg_weights\": True, \"width_indicator\": 2}\n",
    "                        ]\n",
    "                    },\n",
    "                    \"elasticity\": {\n",
    "                        \"available_elasticity_dims\": [\"width\", \"depth\"]\n",
    "                    }\n",
    "                },\n",
    "                \"search\": {\n",
    "                    \"algorithm\": \"NSGA2\",\n",
    "                    \"num_evals\": 2, #30,\n",
    "                    \"population\": 1, # 5,\n",
    "                    \"ref_acc\": model_top1_acc.item(),\n",
    "                    \"acc_delta\": 4\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "# define optimizer\n",
    "init_lr = 3e-4\n",
    "compression_lr = init_lr / 10\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=compression_lr)\n",
    "\n",
    "# Setup\n",
    "nncf_config = NNCFConfig.from_dict(config)\n",
    "\n",
    "bn_adapt_args = BNAdaptationInitArgs(data_loader=wrap_dataloader_for_init(train_loader), device=device)\n",
    "nncf_config.register_extra_structs([bn_adapt_args])\n",
    "\n",
    "nncf_network = create_nncf_network(model, nncf_config)\n",
    "\n",
    "\n",
    "# Training\n",
    "def train_epoch_fn(loader, model, compression_ctrl, epoch, optimizer):\n",
    "    train_epoch(loader, model, device, criterion, optimizer, epoch, compression_ctrl, train_iters=train_steps)\n",
    "\n",
    "training_algorithm = EpochBasedTrainingAlgorithm.from_config(nncf_network, nncf_config)\n",
    "\n",
    "\n",
    "nncf_network, elasticity_ctrl = training_algorithm.run(train_epoch_fn, train_loader,\n",
    "                                                       validate, val_loader, optimizer,\n",
    "                                                       OUTPUT_DIR, None,\n",
    "                                                       train_steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for sub-networks\n",
    "Use NSGA2 Search algorithm to obtain the best sub-network\n",
    "Once the super-network has been trained, use NSGA2 (as specified in configuration) to obtain the best sub-network to satisfy the user's requirements. The configuration of the discovered sub-network(s) and ther performance metrics are returned to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_algo = SearchAlgorithm.from_config(nncf_network, elasticity_ctrl, nncf_config)\n",
    "\n",
    "def validate_model_fn_top1(model, val_loader):\n",
    "    top1, _, _ = validate(model, device, val_loader, criterion)\n",
    "    return top1.item()\n",
    "\n",
    "elasticity_ctrl, best_config, performance_metrics = search_algo.run(validate_model_fn_top1, val_loader,\n",
    "                                                                    OUTPUT_DIR,\n",
    "                                                                    tensorboard_writer=None)\n",
    "\n",
    "print(\"Best config: {best_config}\".format(best_config=best_config))\n",
    "print(\"Performance metrics: {performance_metrics}\".format(performance_metrics=performance_metrics))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the search stage\n",
    "After the search has concluded, we can visualize the search progression phase as a PNG file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_algo.visualize_search_progression(filename=Path(OUTPUT_DIR / (BASE_MODEL_NAME + \"_search\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ie = Core()\n",
    "ie.get_property(device_name=\"CPU\", name=\"FULL_DEVICE_NAME\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "K5HPrY_d-7cV",
    "E01dMaR2_AFL",
    "qMnYsGo9_MA8",
    "L0tH9KdwtHhV"
   ],
   "name": "NNCF Quantization PyTorch Demo (tiny-imagenet/resnet-18)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e5654e4040bf9c32f9079373e7e073bea8a90b10cc5c7486a6257e4930005de1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
