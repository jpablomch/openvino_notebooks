{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9c2cbeb-fe8b-4e09-9432-4f4f4bfddc9c",
   "metadata": {},
   "source": [
    "## Image Inpainting using OpenVINO\n",
    "This notebook demonstrates how to use gmcnn image inpainting model with OpenVINO.\n",
    "The Following pipeline will be created in this notebook.\n",
    "<img align='center' src=\"data/pipeline.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "\n",
    "This model is used to obtain something very similar to the original image given a tampered image.\n",
    "More details about the [GMCNN model](https://github.com/shepnerd/inpainting_gmcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb231ad5-4fd9-4eb2-bf6b-6c1e511a4d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from openvino.runtime import Core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6815624-1f04-4110-8f3e-1da9f1a02cf8",
   "metadata": {},
   "source": [
    "### Downloading the Models\n",
    "Models can be downloaded from omz downloader. omz is a command line tool for downloading models from the open model zoo.\n",
    "`gmcnn-places2-tf` is the omz name for the considered model. You can find the names of available models [here](https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/public/index.md) and [here](https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/intel/index.md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507f58c9-fd68-46b8-9476-127add5cbbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where model will be downloaded\n",
    "base_model_dir = \"model\"\n",
    "# Model name as named in Open Model Zoo\n",
    "model_name = \"gmcnn-places2-tf\"\n",
    "\n",
    "model_path = Path(f\"{base_model_dir}/public/{model_name}/{model_name}/frozen_model.pb\")\n",
    "if not model_path.exists():\n",
    "    download_command = f\"omz_downloader \" \\\n",
    "                       f\"--name {model_name} \" \\\n",
    "                       f\"--output_dir {base_model_dir}\"\n",
    "    ! $download_command\n",
    "else:\n",
    "    print(\"Already downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e649526-4cd8-41fd-9b48-3590f02b5a63",
   "metadata": {},
   "source": [
    "### Convert Tensorflow model to OpenVINO IR format\n",
    "\n",
    "We will be using the model optimizer command line tool for converting the tensorflow model to IR format. \n",
    "\n",
    "We will extract the necessary information from [the overview of openvino models](https://docs.openvino.ai/latest/omz_models_model_gmcnn_places2_tf.html) (alternatively you can check the openvino/open_model_zoo as well)\n",
    "\n",
    "`input_model` path to the tensorflow model.\n",
    "\n",
    "`input shape` input shape of the model, in this case we have 2 inputs given with a commaa seperating the 2 shapes.\n",
    "\n",
    "`input` Used to give the input names. This is essential here because we have 2 inputs.\n",
    "\n",
    "`output_dir` Output directory/name.\n",
    "\n",
    "For more details about the parameters please check [here](https://docs.openvino.ai/latest/openvino_docs_MO_DG_prepare_model_convert_model_Converting_Model.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60b11d7-b3a4-4e2b-bf99-7de0c8eda6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = \"FP32\"\n",
    "ir_path = Path(f\"{base_model_dir}/public/{model_name}/{precision}/{model_name}.xml\")\n",
    "\n",
    "# Run Model Optimizer if the IR model file does not exist\n",
    "if not ir_path.exists():\n",
    "    print(\"Exporting TensorFlow model to IR... This may take a few minutes.\")\n",
    "    convert_command = f\"omz_converter \" \\\n",
    "                      f\"--name {model_name} \" \\\n",
    "                      f\"--download_dir {base_model_dir} \" \\\n",
    "                      f\"--precisions {precision}\"\n",
    "    ! $convert_command\n",
    "else:\n",
    "    print(\"IR model already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5020e38a-0537-4243-b716-b12e5e21e62b",
   "metadata": {},
   "source": [
    "### Load the model\n",
    "\n",
    "Now we will load the IR formatted model.\n",
    "\n",
    " 1. Initialize inference engine (IECore)\n",
    " 2. Read the network from *.bin and *.xml files (weights and architecture)\n",
    " 3. Load the model on the \"CPU.\"\n",
    " 4. Get input and output names of nodes.\n",
    "\n",
    "Only a few lines of code are required to run the model. Let's see it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc07099e-76a2-497b-97b4-2b83ba8e2950",
   "metadata": {},
   "outputs": [],
   "source": [
    "core = Core()\n",
    "\n",
    "# Read the model.xml and weights file\n",
    "model = core.read_model(model=ir_path)\n",
    "# load the model on to the CPU\n",
    "compiled_model = core.compile_model(model=model, device_name=\"CPU\")\n",
    "# Store the input node names as a list because this model has 2 inputs\n",
    "input_layers = list(compiled_model.inputs)\n",
    "output_layer = compiled_model.output(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93076d61-68d9-4c44-b73d-9ac687560eb5",
   "metadata": {},
   "source": [
    "### Determine the input shapes of the model\n",
    "\n",
    "Lets save input shapes into a list called `input_shapes` \n",
    "Note that both the image dimentions are same however the second input shape has a channel of 1 (monotone)\n",
    "\n",
    "*since input dimentions are used for resizing we have copied it to H and W variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2606632b-41a3-41e4-88ae-935029ec87df",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, H, W, C = input_layers[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b641584-e018-49ce-a7df-f48d1eae1d52",
   "metadata": {},
   "source": [
    "### Create a square mask\n",
    "\n",
    "Next we will create a single channeled mask that will be laid on top of the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885c49ff-34bc-476e-b47b-9dd37e4edc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(image_width, image_height, size_x=30, size_y=30, number=1):\n",
    "    \"\"\"\n",
    "    Create a square mask of defined size on a random location\n",
    "\n",
    "    :param: image_width: width of the image\n",
    "    :param: image_height: height of the image\n",
    "    :param: size: size in pixels of one side\n",
    "    :returns:\n",
    "            mask: grayscale float32 mask of size [image_height,image_width,1]\n",
    "    \"\"\"\n",
    "    \n",
    "    mask = np.zeros((image_height, image_width, 1), dtype=np.float32)\n",
    "    for _ in range(number):\n",
    "        start_x = np.random.randint(image_width - size_x)\n",
    "        start_y = np.random.randint(image_height - size_y)\n",
    "        cv2.rectangle(img=mask, pt1=(start_x, start_y), pt2=(start_x + size_x, start_y + size_y), color=(1, 1, 1), thickness=cv2.FILLED)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54d4d89-e7e4-46f7-b58f-858c2f8474c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a square mask of size WxH with number of \"holes\"\n",
    "mask = create_mask(image_width=W, image_height=H, size_x=50, size_y=50, number=10)\n",
    "# This mask will be laid over the input image as noise\n",
    "plt.imshow(cv2.cvtColor(mask, cv2.COLOR_BGR2RGB));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2561cfd2-f1ac-4121-99ad-019c174a10a8",
   "metadata": {},
   "source": [
    "### Load and Resize the Image\n",
    "\n",
    "This image will be altered using a mask. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce844f-35c0-4594-a4d4-c8fb1946c7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Image\n",
    "image = cv2.imread(\"data/test_image.png\")\n",
    "# Resize image to meet network expected input sizes\n",
    "resized_image = cv2.resize(src=image, dsize=(W, H), interpolation=cv2.INTER_AREA)\n",
    "plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af065568-7487-4cd8-9ca2-2343c9ccab3a",
   "metadata": {},
   "source": [
    "### Generating the Masked Image\n",
    "\n",
    "This is the multiplication of the image and the mask gives us the result of the masked image layered on top of the original image. \n",
    "\n",
    "The `masked_image` will be the first input to GMCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f93f1d1-a698-4583-989c-8c7b7bcdfafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating masked image\n",
    "masked_image = (resized_image * (1 - mask) + 255 * mask).astype(np.uint8)\n",
    "plt.imshow(cv2.cvtColor(masked_image, cv2.COLOR_BGR2RGB));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3807058c-dfbe-49cd-8dc1-7008c940b529",
   "metadata": {},
   "source": [
    "### Preprocessing function to aling with the ```input_shapes```\n",
    "\n",
    "The model expects the input dimentions to be NCHW.\n",
    "\n",
    "- masked_image.shape = (512,680,3) -----> model excepts = (1,3,512,680)\n",
    "- resized_mask.shape = (512,680,1) -----> model excepts = (1,1,512,680)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45b4418",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "masked_image = masked_image[None, ...]\n",
    "mask = mask[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31410a7c-54d0-471c-9bf3-24d6cf9e4ec5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result = compiled_model([masked_image, mask])[output_layer]\n",
    "plt.imshow(cv2.cvtColor(result.squeeze().astype(np.uint8), cv2.COLOR_BGR2RGB))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}